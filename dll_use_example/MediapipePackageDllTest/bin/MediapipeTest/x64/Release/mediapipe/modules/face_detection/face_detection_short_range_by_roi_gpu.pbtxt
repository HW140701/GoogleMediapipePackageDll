# MediaPipe graph to detect faces. (CPU input, and inference is executed on
# CPU.)
#
# It is required that "face_detection_short_range.tflite" is available at
# "mediapipe/modules/face_detection/face_detection_short_range.tflite"
# path during execution.
#
# EXAMPLE:
#   node {
#     calculator: "FaceDetectionShortRangeByRoiGpu"
#     input_stream: "IMAGE:image"
#     input_stream: "ROI:roi"
#     output_stream: "DETECTIONS:face_detections"
#   }

type: "FaceDetectionShortRangeByRoiGpu"

# GPU image. (GpuBuffer)
input_stream: "IMAGE:image"

# ROI (region of interest) within the given image where faces should be
# detected. (NormalizedRect)
input_stream: "ROI:roi"

# Detected faces. (std::vector<Detection>)
# NOTE: there will not be an output packet in the DETECTIONS stream for this
# particular timestamp if none of faces detected. However, the MediaPipe
# framework will internally inform the downstream calculators of the absence of
# this packet so that they don't wait for it unnecessarily.
output_stream: "DETECTIONS:detections"

# Converts the input GPU image (GpuBuffer) to the multi-backend image type
# (Image).
node: {
  calculator: "ToImageCalculator"
  input_stream: "IMAGE_GPU:image"
  output_stream: "IMAGE:multi_backend_image"
}

# Transforms specified region of image into 128x128 tensor keeping aspect ratio
# (padding tensor if needed).
node {
  calculator: "ImageToTensorCalculator"
  input_stream: "IMAGE:multi_backend_image"
  input_stream: "NORM_RECT:roi"
  output_stream: "TENSORS:input_tensors"
  output_stream: "MATRIX:transform_matrix"
  options: {
    [mediapipe.ImageToTensorCalculatorOptions.ext] {
      output_tensor_width: 128
      output_tensor_height: 128
      keep_aspect_ratio: true
      output_tensor_float_range {
        min: -1.0
        max: 1.0
      }
      border_mode: BORDER_ZERO
      gpu_origin: TOP_LEFT
    }
  }
}

# Runs a TensorFlow Lite model on GPU that takes an image tensor and outputs a
# vector of tensors representing, for instance, detection boxes/keypoints and
# scores.
node {
  calculator: "InferenceCalculator"
  input_stream: "TENSORS:input_tensors"
  output_stream: "TENSORS:detection_tensors"
  options: {
    [mediapipe.InferenceCalculatorOptions.ext] {
      model_path: "mediapipe/modules/face_detection/face_detection_short_range.tflite"
    }
  }
}

# Performs tensor post processing to generate face detections.
node {
  calculator: "FaceDetectionShortRangeCommon"
  input_stream: "TENSORS:detection_tensors"
  input_stream: "MATRIX:transform_matrix"
  output_stream: "DETECTIONS:detections"
}
